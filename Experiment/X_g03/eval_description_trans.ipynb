{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "import pm4py\n",
    "from pm4py.objects.bpmn.obj import BPMN\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bpmn = pm4py.read_bpmn('X_G03_text.bpmn')\n",
    "model = SentenceTransformer(\"Maite89/Roberta_finetuning_semantic_similarity_stsb_multi_mt\")\n",
    "Activities_text=[]\n",
    "relations=[('select a starting block', 'run for 5km', 'parallel_gateway'),\n",
    "('select a starting block', 'measure the time', 'parallel_gateway'),\n",
    "('run for 5km', 'check the measured time', 'Flow'),\n",
    "('measure the time', 'check the measured time', 'Flow'),\n",
    "('check the measured time', 'you are good', 'XOR_gateway'),\n",
    "('check the measured time', 'need to train and check until you have achieved this goal', 'XOR_gateway'),\n",
    "('can do it in less than 25 minutes', 'you are good', 'XOR_condition'),\n",
    "('cannot do it in less than 25 minutes', 'need to train and check until you have achieved this goal', 'XOR_condition'),\n",
    "('you are good', 'get your starting number', 'Flow'),\n",
    "('get your starting number', 'check starting time', 'Flow'),\n",
    "('check starting time', 'go there from home', 'XOR_gateway'),\n",
    "('check starting time', 'leave directly from work', 'XOR_gateway'),\n",
    "('more than one hour is left between your starting time and the end of your workday', 'go there from home', 'XOR_condition'),\n",
    "('one hour or less is left between your starting time and the end of your workday', 'leave directly from work', 'XOR_condition'),\n",
    "('running at the Night Run', 'run and drink at the same time', 'Flow'),\n",
    "('run and drink at the same time', 'receive your final running time', 'Flow')]\n",
    "df_text = pd.DataFrame(columns=['Source', 'Target', 'Relation'])\n",
    "for relation in relations:\n",
    "    df_text = df_text.append({'Source': relation[0], 'Target': relation[1], 'Relation': relation[2]}, ignore_index=True)\n",
    "    Activities_text.append(relation[1])\n",
    "    if relation[2]!='XOR_condition':\n",
    "        Activities_text.append(relation[0])\n",
    "queries=list(set(Activities_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: 0.5625\n",
      "recall: 0.45\n"
     ]
    }
   ],
   "source": [
    "# def detect_text_and_model(bpmn,queries,model):\n",
    "Activities_BPMN=[]\n",
    "for node in bpmn.get_nodes():\n",
    "    if(isinstance(node,BPMN.EndEvent) or isinstance(node,BPMN.StartEvent)):\n",
    "        continue\n",
    "    if(isinstance(node,BPMN.Activity) or isinstance(node,BPMN.Event)):\n",
    "        Activities_BPMN.append(node.name)\n",
    "\n",
    "# entity match\n",
    "df = pd.DataFrame(columns=['text', 'BPMN', 'score'])\n",
    "temp_list=[]\n",
    "for query in queries:\n",
    "    query_embedding = torch.FloatTensor(model.encode(query))\n",
    "    scores=[]\n",
    "    for activity in Activities_BPMN:\n",
    "        activity_embedding = torch.FloatTensor(model.encode(activity))\n",
    "        cos_sim = F.cosine_similarity(query_embedding, activity_embedding, dim=0)\n",
    "        scores.append(cos_sim.item())\n",
    "    # print(scores)\n",
    "    max_score_pos=np.argmax(scores)\n",
    "    max_score=np.max(scores)\n",
    "    if(max_score<0.5):\n",
    "        df = df.append({'text': query, 'BPMN': \"No match found\", 'score': max_score}, ignore_index=True)\n",
    "    else:\n",
    "        if(max_score_pos in temp_list):\n",
    "            score_tep=df.loc[df['BPMN']==Activities_BPMN[max_score_pos]]['score'].tolist()[0]\n",
    "            if(max_score>score_tep):\n",
    "                df.loc[df['BPMN']==Activities_BPMN[max_score_pos],'BPMN']=\"No match found\"\n",
    "                df = df.append({'text': query, 'BPMN': Activities_BPMN[max_score_pos], 'score': max_score}, ignore_index=True)\n",
    "            else:\n",
    "                df = df.append({'text': query, 'BPMN': \"No match found\", 'score': max_score}, ignore_index=True)\n",
    "        else:\n",
    "            temp_list.append(max_score_pos)\n",
    "            df = df.append({'text': query, 'BPMN': Activities_BPMN[max_score_pos], 'score': max_score}, ignore_index=True)\n",
    "for i in range(len(Activities_BPMN)):\n",
    "    if i not in temp_list:\n",
    "        df = df.append({'text': \"No match found\", 'BPMN': Activities_BPMN[i], 'score': 0}, ignore_index=True)\n",
    "\n",
    "# model relations（text）\n",
    "# bpmn = pm4py.read_bpmn('6.bpmn2.bpmn')\n",
    "temp=[]\n",
    "for flow in bpmn.get_flows():\n",
    "    temp.append([flow.source,flow.target,flow.get_name()])\n",
    "\n",
    "for rel in temp:\n",
    "    if(isinstance(rel[1],BPMN.Gateway) and len(rel[1].get_in_arcs())>1):\n",
    "        rel[1]=rel[1].get_out_arcs()[0].target\n",
    "        while(isinstance(rel[1],BPMN.Gateway)):\n",
    "            rel[1]=rel[1].get_out_arcs()[0].target\n",
    "\n",
    "temp1=[]\n",
    "for rel in temp:\n",
    "    if(rel[0]==rel[1]):\n",
    "        continue\n",
    "    elif(isinstance(rel[0],BPMN.Gateway) and len(rel[0].get_in_arcs())>1):\n",
    "        continue\n",
    "    else:\n",
    "        temp1.append(rel)\n",
    "df_BPMN = pd.DataFrame(columns=['Source', 'Target', 'Relation'])\n",
    "for rel in temp1:\n",
    "    if(isinstance(rel[1],BPMN.EndEvent) or isinstance(rel[0],BPMN.StartEvent)):\n",
    "        continue\n",
    "    if(isinstance(rel[0],BPMN.ExclusiveGateway)):\n",
    "        # temp2.append([rel[0].get_in_arcs()[0].source, rel[1]])\n",
    "        df_BPMN = df_BPMN.append({'Source': rel[0].get_in_arcs()[0].source.name, 'Target': rel[1].name, 'Relation': 'XOR_gateway'}, ignore_index=True)\n",
    "        df_BPMN = df_BPMN.append({'Source': rel[2], 'Target': rel[1].name, 'Relation': 'XOR_condition'}, ignore_index=True)\n",
    "        # print([rel[0].get_in_arcs()[0].source, rel[1]])\n",
    "    elif(isinstance(rel[1],BPMN.ExclusiveGateway)):\n",
    "        continue\n",
    "    elif(isinstance(rel[0],BPMN.ParallelGateway)):\n",
    "        df_BPMN = df_BPMN.append({'Source': rel[0].get_in_arcs()[0].source.name, 'Target': rel[1].name, 'Relation': 'parallel_gateway'}, ignore_index=True)\n",
    "    elif(isinstance(rel[1],BPMN.ParallelGateway)):\n",
    "        continue\n",
    "    else:\n",
    "        df_BPMN = df_BPMN.append({'Source': rel[0].name, 'Target': rel[1].name, 'Relation': 'Flow'}, ignore_index=True)\n",
    "\n",
    "# replace\n",
    "df_text_new = pd.DataFrame(columns=['Source', 'Target', 'Relation'])\n",
    "for row in df_text.itertuples(index=False):\n",
    "    source=row.Source\n",
    "    target=row.Target\n",
    "    relation=row.Relation\n",
    "    if(source!=\"No match found\"):\n",
    "        if(len(df.loc[df['text']==source]['BPMN'].tolist())>0):\n",
    "            if(df.loc[df['text']==source]['BPMN'].tolist()[0]!=\"No match found\"):\n",
    "                source=df.loc[df['text']==source]['BPMN'].tolist()[0]\n",
    "    if(target!=\"No match found\"):\n",
    "        if(len(df.loc[df['text']==target]['BPMN'].tolist())>0):\n",
    "            if(df.loc[df['text']==target]['BPMN'].tolist()[0]!=\"No match found\"):\n",
    "                target=df.loc[df['text']==target]['BPMN'].tolist()[0]\n",
    "    df_text_new = df_text_new.append({'Source': source, 'Target': target, 'Relation': relation}, ignore_index=True)\n",
    "\n",
    "df_text_new.loc[6,'Source']='yes'\n",
    "df_text_new.loc[7,'Source']='no'\n",
    "df_text_new.loc[12,'Source']='yes'\n",
    "df_text_new.loc[13,'Source']='no'\n",
    "list_text=[]\n",
    "for row in df_text_new.itertuples(index=False):\n",
    "    list_text.append((row.Source,row.Target,row.Relation))\n",
    "list_BPMN=[]\n",
    "for row in df_BPMN.itertuples(index=False):\n",
    "    list_BPMN.append((row.Source,row.Target,row.Relation))\n",
    "len(set(list_text).intersection(set(list_BPMN)))\n",
    "precision=len(set(list_text).intersection(set(list_BPMN)))/len(list_text)\n",
    "recall=len(set(list_text).intersection(set(list_BPMN)))/(len(list_BPMN))\n",
    "print('precision:',precision)\n",
    "print('recall:',recall)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trochtest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
